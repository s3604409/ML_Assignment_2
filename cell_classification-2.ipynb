{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 23:40:04.835036: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-12 23:40:05.016632: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/pupilmesh3/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-05-12 23:40:05.016659: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-12 23:40:06.147875: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/pupilmesh3/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-05-12 23:40:06.148020: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/pupilmesh3/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2023-05-12 23:40:06.148037: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"dataset/data_labels_mainData.csv\"\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting data from the CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataframe, img_folder):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        img_name = row['ImageName']\n",
    "        img_path = os.path.join(img_folder, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        data.append(img)\n",
    "        labels.append(row['cellTypeName'])\n",
    "    \n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "img_folder = \"dataset/patch_images/\"\n",
    "data, labels = load_data(df, img_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)\n",
    "\n",
    "# Normalize the image data\n",
    "data = data.astype('float32') / 255.0\n",
    "\n",
    "# Split the dataset into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, encoded_labels, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "\n",
    "# Apply data augmentation\n",
    "augmented_data = []\n",
    "augmented_labels = []\n",
    "\n",
    "for img, label in zip(data, encoded_labels):\n",
    "    img = img.reshape((1, *img.shape))\n",
    "    for _ in range(4):  # Number of times to augment each image\n",
    "        augmented_img = datagen.flow(img, batch_size=1)[0].reshape(img.shape[1:])\n",
    "        augmented_data.append(augmented_img)\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "augmented_data = np.array(augmented_data)\n",
    "augmented_labels = np.array(augmented_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into training and testing subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(augmented_data, augmented_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Sample Images with Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to get the label name from the label index\n",
    "def get_label_name(index):\n",
    "    label_map = {0: 'fibroblast', 1: 'inflammatory', 2: 'epithelial', 3: 'others'}\n",
    "    return label_map[index]\n",
    "\n",
    "# Define a function to display sample images with their labels\n",
    "def display_sample_images(images, labels, num_samples=5):\n",
    "    indices = np.random.choice(range(len(images)), num_samples, replace=False)\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 3))\n",
    "    \n",
    "    for i, ax in zip(indices, axes):\n",
    "        ax.imshow(images[i])\n",
    "        ax.set_title(get_label_name(labels[i]))\n",
    "        ax.axis('off')\n",
    "\n",
    "# Display sample images with their labels\n",
    "display_sample_images(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries for SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction using HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        hog_feature, hog_image = hog(img, orientations=8, pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(1, 1), visualize=True, channel_axis=-1)\n",
    "        features.append(hog_feature)\n",
    "    return np.array(features)\n",
    "\n",
    "X_train_hog = extract_hog_features(X_train)\n",
    "X_test_hog = extract_hog_features(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the SVM model with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1, 'kernel': 'rbf'}\n",
      "Best cross-validated accuracy: 0.45043740759694956\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for the SVM model\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_hog, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best cross-validated accuracy:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the SVM model with the Best Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.44\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2989  175   50    0]\n",
      " [1009  437   34    0]\n",
      " [1897  133   56    0]\n",
      " [ 990  116   29    2]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.93      0.59      3214\n",
      "           1       0.51      0.30      0.37      1480\n",
      "           2       0.33      0.03      0.05      2086\n",
      "           3       1.00      0.00      0.00      1137\n",
      "\n",
      "    accuracy                           0.44      7917\n",
      "   macro avg       0.57      0.31      0.25      7917\n",
      "weighted avg       0.50      0.44      0.32      7917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best SVM model on the test set\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_pred_best_svm = best_svm.predict(X_test_hog)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_best_svm)\n",
    "conf_mat = confusion_matrix(y_test, y_pred_best_svm)\n",
    "class_report = classification_report(y_test, y_pred_best_svm)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_mat)\n",
    "print(\"\\nClassification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries for Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf.fit(X_train_hog, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.39\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2099  378  546  191]\n",
      " [ 682  474  248   76]\n",
      " [1234  285  426  141]\n",
      " [ 651  164  241   81]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.65      0.53      3214\n",
      "           1       0.36      0.32      0.34      1480\n",
      "           2       0.29      0.20      0.24      2086\n",
      "           3       0.17      0.07      0.10      1137\n",
      "\n",
      "    accuracy                           0.39      7917\n",
      "   macro avg       0.32      0.31      0.30      7917\n",
      "weighted avg       0.35      0.39      0.36      7917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = rf.predict(X_test_hog)\n",
    "\n",
    "# Calculate the accuracy, confusion matrix, and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_mat)\n",
    "print(\"\\nClassification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding the labels\n",
    "y_train_cnn = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_cnn = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "# Reshaping the image data to include the channel dimension\n",
    "X_train_cnn = X_train.reshape(*X_train.shape, 1)\n",
    "X_test_cnn = X_test.reshape(*X_test.shape, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def create_cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(27, 27, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4, activation='softmax', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "    return model\n",
    "\n",
    "cnn_model = create_cnn_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn_model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5621 - accuracy: 0.8122 - val_loss: 0.5823 - val_accuracy: 0.7938\n",
      "Epoch 2/50\n",
      "693/693 [==============================] - 13s 18ms/step - loss: 0.5541 - accuracy: 0.8153 - val_loss: 0.5735 - val_accuracy: 0.8032\n",
      "Epoch 3/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5546 - accuracy: 0.8144 - val_loss: 0.6278 - val_accuracy: 0.7765\n",
      "Epoch 4/50\n",
      "693/693 [==============================] - 15s 22ms/step - loss: 0.5529 - accuracy: 0.8144 - val_loss: 0.5905 - val_accuracy: 0.7970\n",
      "Epoch 5/50\n",
      "693/693 [==============================] - 13s 19ms/step - loss: 0.5496 - accuracy: 0.8105 - val_loss: 0.5496 - val_accuracy: 0.8109\n",
      "Epoch 6/50\n",
      "693/693 [==============================] - 13s 19ms/step - loss: 0.5501 - accuracy: 0.8164 - val_loss: 0.9631 - val_accuracy: 0.7190\n",
      "Epoch 7/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5577 - accuracy: 0.8113 - val_loss: 0.5272 - val_accuracy: 0.8211\n",
      "Epoch 8/50\n",
      "693/693 [==============================] - 13s 19ms/step - loss: 0.5484 - accuracy: 0.8177 - val_loss: 0.6912 - val_accuracy: 0.7521\n",
      "Epoch 9/50\n",
      "693/693 [==============================] - 13s 19ms/step - loss: 0.5530 - accuracy: 0.8138 - val_loss: 1.1327 - val_accuracy: 0.5911\n",
      "Epoch 10/50\n",
      "693/693 [==============================] - 13s 19ms/step - loss: 0.5461 - accuracy: 0.8126 - val_loss: 1.0442 - val_accuracy: 0.5726\n",
      "Epoch 11/50\n",
      "693/693 [==============================] - 13s 19ms/step - loss: 0.5456 - accuracy: 0.8179 - val_loss: 0.5653 - val_accuracy: 0.8065\n",
      "Epoch 12/50\n",
      "693/693 [==============================] - 13s 19ms/step - loss: 0.5504 - accuracy: 0.8140 - val_loss: 0.5652 - val_accuracy: 0.8082\n",
      "Epoch 13/50\n",
      "693/693 [==============================] - 13s 19ms/step - loss: 0.5462 - accuracy: 0.8147 - val_loss: 0.5829 - val_accuracy: 0.8016\n",
      "Epoch 14/50\n",
      "693/693 [==============================] - 13s 19ms/step - loss: 0.5461 - accuracy: 0.8196 - val_loss: 0.6290 - val_accuracy: 0.7727\n",
      "Epoch 15/50\n",
      "693/693 [==============================] - 13s 19ms/step - loss: 0.5473 - accuracy: 0.8163 - val_loss: 0.7018 - val_accuracy: 0.7530\n",
      "Epoch 16/50\n",
      "693/693 [==============================] - 13s 19ms/step - loss: 0.5453 - accuracy: 0.8185 - val_loss: 0.6793 - val_accuracy: 0.7617\n",
      "Epoch 17/50\n",
      "693/693 [==============================] - 13s 19ms/step - loss: 0.5474 - accuracy: 0.8149 - val_loss: 0.6693 - val_accuracy: 0.7658\n",
      "Epoch 18/50\n",
      "693/693 [==============================] - 13s 19ms/step - loss: 0.5427 - accuracy: 0.8187 - val_loss: 0.6311 - val_accuracy: 0.7797\n",
      "Epoch 19/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5458 - accuracy: 0.8181 - val_loss: 0.7984 - val_accuracy: 0.7633\n",
      "Epoch 20/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5372 - accuracy: 0.8186 - val_loss: 0.8557 - val_accuracy: 0.6774\n",
      "Epoch 21/50\n",
      "693/693 [==============================] - 15s 21ms/step - loss: 0.5421 - accuracy: 0.8178 - val_loss: 0.6848 - val_accuracy: 0.7579\n",
      "Epoch 22/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5446 - accuracy: 0.8189 - val_loss: 0.6029 - val_accuracy: 0.7858\n",
      "Epoch 23/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5419 - accuracy: 0.8164 - val_loss: 0.6333 - val_accuracy: 0.7788\n",
      "Epoch 24/50\n",
      "693/693 [==============================] - 13s 19ms/step - loss: 0.5411 - accuracy: 0.8191 - val_loss: 0.5658 - val_accuracy: 0.8061\n",
      "Epoch 25/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5415 - accuracy: 0.8181 - val_loss: 0.5207 - val_accuracy: 0.8222\n",
      "Epoch 26/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5478 - accuracy: 0.8175 - val_loss: 0.8587 - val_accuracy: 0.7330\n",
      "Epoch 27/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5381 - accuracy: 0.8223 - val_loss: 1.9935 - val_accuracy: 0.4372\n",
      "Epoch 28/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5449 - accuracy: 0.8179 - val_loss: 0.6174 - val_accuracy: 0.7777\n",
      "Epoch 29/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5351 - accuracy: 0.8216 - val_loss: 0.6760 - val_accuracy: 0.7735\n",
      "Epoch 30/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5317 - accuracy: 0.8228 - val_loss: 0.8466 - val_accuracy: 0.6860\n",
      "Epoch 31/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5351 - accuracy: 0.8224 - val_loss: 0.5725 - val_accuracy: 0.8041\n",
      "Epoch 32/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5363 - accuracy: 0.8220 - val_loss: 0.7129 - val_accuracy: 0.7672\n",
      "Epoch 33/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5385 - accuracy: 0.8213 - val_loss: 0.7556 - val_accuracy: 0.7288\n",
      "Epoch 34/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5417 - accuracy: 0.8203 - val_loss: 0.6231 - val_accuracy: 0.7889\n",
      "Epoch 35/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5354 - accuracy: 0.8215 - val_loss: 0.5419 - val_accuracy: 0.8135\n",
      "Epoch 36/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5426 - accuracy: 0.8199 - val_loss: 0.5677 - val_accuracy: 0.8039\n",
      "Epoch 37/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5360 - accuracy: 0.8204 - val_loss: 0.5298 - val_accuracy: 0.8210\n",
      "Epoch 38/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5352 - accuracy: 0.8220 - val_loss: 1.2836 - val_accuracy: 0.4670\n",
      "Epoch 39/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5395 - accuracy: 0.8186 - val_loss: 0.7400 - val_accuracy: 0.7272\n",
      "Epoch 40/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5313 - accuracy: 0.8271 - val_loss: 0.9354 - val_accuracy: 0.7300\n",
      "Epoch 41/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5406 - accuracy: 0.8202 - val_loss: 0.5287 - val_accuracy: 0.8176\n",
      "Epoch 42/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5332 - accuracy: 0.8220 - val_loss: 0.8335 - val_accuracy: 0.7575\n",
      "Epoch 43/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5310 - accuracy: 0.8230 - val_loss: 0.5473 - val_accuracy: 0.8109\n",
      "Epoch 44/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5314 - accuracy: 0.8215 - val_loss: 0.6705 - val_accuracy: 0.7666\n",
      "Epoch 45/50\n",
      "693/693 [==============================] - 14s 20ms/step - loss: 0.5381 - accuracy: 0.8203 - val_loss: 0.6440 - val_accuracy: 0.7735\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_cnn_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "history = cnn_model.fit(X_train_cnn, y_train_cnn,\n",
    "                        batch_size=32,\n",
    "                        epochs=50,\n",
    "                        validation_split=0.3,\n",
    "                        callbacks=[early_stopping, model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248/248 [==============================] - 1s 5ms/step\n",
      "Accuracy: 0.82\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2935  163   85   31]\n",
      " [  67 1209  109   95]\n",
      " [ 114  179 1605  188]\n",
      " [  79  170  149  739]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92      3214\n",
      "           1       0.70      0.82      0.76      1480\n",
      "           2       0.82      0.77      0.80      2086\n",
      "           3       0.70      0.65      0.67      1137\n",
      "\n",
      "    accuracy                           0.82      7917\n",
      "   macro avg       0.79      0.79      0.79      7917\n",
      "weighted avg       0.82      0.82      0.82      7917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_cnn = np.argmax(cnn_model.predict(X_test_cnn), axis=-1)\n",
    "\n",
    "# Calculate the accuracy, confusion matrix, and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred_cnn)\n",
    "conf_mat = confusion_matrix(y_test, y_pred_cnn)\n",
    "class_report = classification_report(y_test, y_pred_cnn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_mat)\n",
    "print(\"\\nClassification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the End-to-End Machine Learning System\n",
    "\n",
    "### Evaluation Framework\n",
    "- We used a train-test split (80/20) to separate our dataset into training and test sets. This helps us to evaluate the performance of our models on unseen data.\n",
    "\n",
    "### Data Pre-processing\n",
    "- We read the data from the CSV file, extracted the images and their corresponding labels, and normalized the image pixel values to the range [0, 1].\n",
    "\n",
    "### Baseline Models\n",
    "- We chose three different machine learning algorithms: Support Vector Machine (SVM) with HOG features, Random Forest Classifier with HOG features, and a Convolutional Neural Network (CNN).\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "- We used the default hyperparameters for the SVM and Random Forest models. For the CNN model, we used the Adam optimizer with a learning rate of 0.001 and an early stopping callback to avoid overfitting. We can further optimize the models using techniques like GridSearchCV or RandomizedSearchCV for hyperparameter tuning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Comparison and Analysis\n",
    "\n",
    "We trained and evaluated three different models on the histopathology image dataset. Here is a summary of their performance:\n",
    "\n",
    "1. **Support Vector Machine (SVM) with HOG features**: 44% accuracy\n",
    "2. **Random Forest Classifier with HOG features**: 39% accuracy\n",
    "3. **Convolutional Neural Network (CNN)**: 82% accuracy\n",
    "\n",
    "### Analysis\n",
    "\n",
    "The **SVM and Random Forest models** have relatively low accuracies compared to the CNN model. The main reason for this performance difference is that both SVM and Random Forest models rely on handcrafted HOG features, which may not capture the complex patterns present in histopathology images. Moreover, these traditional machine learning algorithms are not specifically designed to handle image data, and their performance is highly dependent on the quality of the extracted features.\n",
    "\n",
    "On the other hand, the **CNN model** has a significantly higher accuracy of 82%. This is because CNNs are specifically designed to work with image data and are capable of automatically learning complex hierarchical features from the images themselves. CNNs consist of convolutional and pooling layers that can capture local and global patterns, which are crucial for classifying histopathology images. As a result, CNNs generally perform better on image classification tasks compared to traditional machine learning algorithms that rely on handcrafted features.\n",
    "\n",
    "To further improve the performance of the models, we can explore techniques such as more data augmentation, hyperparameter tuning, and more advanced CNN architectures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
