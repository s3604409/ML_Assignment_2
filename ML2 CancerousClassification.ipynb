{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f11a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.feature import hog\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498cd643",
   "metadata": {},
   "source": [
    "## Initializing/Import Data + Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c705459",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"dataset/data_labels_mainData.csv\"\n",
    "mainData_df = pd.read_csv(csv_file)\n",
    "\n",
    "def load_data(dataframe, img_folder):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        img_name = row['ImageName']\n",
    "        img_path = os.path.join(img_folder, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        data.append(img)\n",
    "        labels.append(row['isCancerous'])\n",
    "    \n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "img_folder = \"dataset/patch_images/\"\n",
    "data, labels = load_data(mainData_df, img_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3368883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing isCancerous column to bool\n",
    "mainData_df['isCancerous'] = mainData_df['isCancerous'].astype('bool')\n",
    "# Normalize the image data\n",
    "data = data.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d2a88d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4509f9a244cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Number of times to augment each image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0maugmented_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0maugmented_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maugmented_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0maugmented_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         ]\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             x = self.image_data_generator.apply_transform(\n\u001b[0m\u001b[0;32m    802\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mapply_transform\u001b[1;34m(self, x, transform_parameters)\u001b[0m\n\u001b[0;32m   2009\u001b[0m         \u001b[0mimg_channel_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannel_axis\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2011\u001b[1;33m         x = apply_affine_transform(\n\u001b[0m\u001b[0;32m   2012\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2013\u001b[0m             \u001b[0mtransform_parameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"theta\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mapply_affine_transform\u001b[1;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[0;32m   2607\u001b[0m         \u001b[0mfinal_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2609\u001b[1;33m         channel_images = [\n\u001b[0m\u001b[0;32m   2610\u001b[0m             ndimage.interpolation.affine_transform(\n\u001b[0;32m   2611\u001b[0m                 \u001b[0mx_channel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2609\u001b[0m         channel_images = [\n\u001b[1;32m-> 2610\u001b[1;33m             ndimage.interpolation.affine_transform(\n\u001b[0m\u001b[0;32m   2611\u001b[0m                 \u001b[0mx_channel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2612\u001b[0m                 \u001b[0mfinal_affine_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\ndimage\\_interpolation.py\u001b[0m in \u001b[0;36maffine_transform\u001b[1;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[0;32m    612\u001b[0m                              mode, cval, npad, False)\n\u001b[0;32m    613\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m         _nd_image.geometric_transform(filtered, None, None, matrix, offset,\n\u001b[0m\u001b[0;32m    615\u001b[0m                                       \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m                                       None)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#image generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "\n",
    "# Apply data augmentation\n",
    "augmented_data = []\n",
    "augmented_labels = []\n",
    "\n",
    "for img, label in zip(data, labels):\n",
    "    img = img.reshape((1, *img.shape))\n",
    "    for _ in range(3):  # Number of times to augment each image\n",
    "        augmented_img = datagen.flow(img, batch_size=1)[0].reshape(img.shape[1:])\n",
    "        augmented_data.append(augmented_img)\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "augmented_data = np.array(augmented_data)\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a8f943",
   "metadata": {},
   "source": [
    "## Model 1.1: Convolutional  Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Neural Network Layers\n",
    "cancerModel = Sequential()\n",
    "\n",
    "cancerModel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(27, 27, 3)))\n",
    "cancerModel.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "cancerModel.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "cancerModel.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "cancerModel.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "cancerModel.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "cancerModel.add(Flatten())\n",
    "cancerModel.add(Dense(128, activation='relu'))\n",
    "cancerModel.add(Dropout(0.5))\n",
    "cancerModel.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Train test val split\n",
    "# X_cnn_train, X_cnn_test, y_cnn_train, y_cnn_test = train_test_split(augmented_data, augmented_labels, test_size=0.3, random_state=2)\n",
    "\n",
    "# # Compile the model\n",
    "# cancerModel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# history = cancerModel.fit(X_cnn_train, y_cnn_train,\n",
    "#                         batch_size=32,\n",
    "#                         epochs=50,\n",
    "#                         validation_split=0.2,\n",
    "#                         callbacks=[early_stopping])\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred_cnn = np.argmax(cancerModel.predict(X_cnn_test), axis=-1)\n",
    "# test_loss, test_accuracy = cancerModel.evaluate(X_cnn_test, y_cnn_test)\n",
    "\n",
    "# # Calculate the accuracy, confusion matrix, and classification report\n",
    "# test_loss, test_accuracy = cancerModel.evaluate(X_cnn_test, y_cnn_test)\n",
    "# cnn_conf_mat = confusion_matrix(y_cnn_test, y_pred_cnn)\n",
    "# cnn_class_report = classification_report(y_cnn_test, y_pred_cnn)\n",
    "\n",
    "# print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "# print(f\"Loss: {test_loss:.4f}\")\n",
    "# print(\"\\nConfusion Matrix:\\n\", cnn_conf_mat)\n",
    "# print(\"\\nClassification Report:\\n\", cnn_class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4547d0ea",
   "metadata": {},
   "source": [
    "## Model 1.2: Parameter Change: Activation Function + Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Building Neural Network Layers\n",
    "cancersigModel = Sequential()\n",
    "\n",
    "cancersigModel.add(Conv2D(32, (3, 3), activation='sigmoid', input_shape=(27, 27, 3)))\n",
    "cancersigModel.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "cancersigModel.add(Conv2D(64, (3, 3), activation='sigmoid'))\n",
    "cancersigModel.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "cancersigModel.add(Conv2D(128, (3, 3), activation='sigmoid'))\n",
    "cancersigModel.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "cancersigModel.add(Flatten())\n",
    "cancersigModel.add(Dense(128, activation='sigmoid'))\n",
    "cancersigModel.add(Dropout(0.5))\n",
    "cancersigModel.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d0e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test val split\n",
    "X_sig_train, X_sig_test, y_sig_train, y_sig_test = train_test_split(augmented_data, augmented_labels, test_size=0.3, random_state=2)\n",
    "\n",
    "# Compile the model\n",
    "cancersigModel.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = cancersigModel.fit(X_sig_train, y_sig_train,\n",
    "                        batch_size=32,\n",
    "                        epochs=50,\n",
    "                        validation_split=0.2,\n",
    "                        callbacks=[early_stopping])\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_sig = np.argmax(cancersigModel.predict(X_sig_test), axis=-1)\n",
    "\n",
    "# Calculate the accuracy, confusion matrix, and classification report\n",
    "test_loss, test_accuracy = cancersigModel.evaluate(X_sig_test, y_sig_test)\n",
    "sig_conf_mat = confusion_matrix(y_sig_test, y_pred_sig)\n",
    "sig_class_report = classification_report(y_sig_test, y_pred_sig)\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Loss: {test_loss:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", sig_conf_mat)\n",
    "print(\"\\nClassification Report:\\n\", sig_class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c17649",
   "metadata": {},
   "source": [
    "## Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab4ef3",
   "metadata": {},
   "source": [
    "## HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8819c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test val split\n",
    "X_rfc_train, X_rfc_test, y_rfc_train, y_rfc_test = train_test_split(augmented_data, augmented_labels, test_size=0.3, random_state=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7424ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        hog_feature, hog_image = hog(img, orientations=8, pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(1, 1), visualize=True)\n",
    "        features.append(hog_feature)\n",
    "    return np.array(features)\n",
    "\n",
    "X_train_hog = extract_hog_features(X_rfc_train)\n",
    "X_test_hog = extract_hog_features(X_rfc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154081e",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ecda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc_classifier.fit(X_train_hog, y_rfc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2964b9a",
   "metadata": {},
   "source": [
    "## Determining the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb8abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],  \n",
    "#     'max_depth': [None, 5, 10],      \n",
    "#     'max_features': ['sqrt', 'log2'] \n",
    "# }\n",
    "\n",
    "# gridsearch = GridSearchCV(estimator=rfc_classifier, param_grid=param_grid, cv=5)\n",
    "# gridsearch.fit(X_train_hog, y_rfc_train)\n",
    "# params = gridsearch.best_params_\n",
    "# print(\"Hyperparameters:\", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c38de9",
   "metadata": {},
   "source": [
    "### Training Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f0215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # recreating model with new parameters\n",
    "# reparam_rfc_classifier = RandomForestClassifier(**params)\n",
    "# reparam_rfc_classifier.fit(X_train_hog, y_rfc_train)\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# rfc_predictions = reparam_rfc_classifier.predict(X_test_hog)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7835322",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace6880",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Evaluate the accuracy of the model\n",
    "# rfc_accuracy = accuracy_score(y_rfc_test, rfc_predictions)\n",
    "# rfc_conf_mat = confusion_matrix(y_rfc_test, rfc_predictions)\n",
    "# rfc_class_report = classification_report(y_rfc_test, rfc_predictions)\n",
    "# print(f\"Accuracy: {rfc_accuracy:.4f}\")\n",
    "# print(\"\\nConfusion Matrix:\\n\", rfc_conf_mat)\n",
    "# print(\"\\nClassification Report:\\n\", rfc_class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1fe08e",
   "metadata": {},
   "source": [
    "## Model 3: CNN + Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc27f34",
   "metadata": {},
   "source": [
    "### From CNN sig in Model 1.2\n",
    "\n",
    "**NOTE: Model 1.2 code MUST be run before using Model 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f7d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer = tf.keras.Model(inputs=cancersigModel.input, outputs=cancersigModel.layers[-2].output)\n",
    "\n",
    "def extract_sig_features(images):\n",
    "    features = target_layer.predict(images)\n",
    "    return features\n",
    "\n",
    "train_sig_features = extract_sig_features(X_sig_train)\n",
    "train_sig_features = train_sig_features.reshape(train_sig_features.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e650cc",
   "metadata": {},
   "source": [
    "### Training Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8cbf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_classifier = RandomForestClassifier()\n",
    "\n",
    "rfc_classifier.fit(train_sig_features, y_sig_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d308c632",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042faae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sig_features = extract_sig_features(X_sig_test)\n",
    "test_sig_features = test_sig_features.reshape(test_sig_features.shape[0], -1)\n",
    "rfsig_predictions = rfc_classifier.predict(test_sig_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfsig_accuracy = accuracy_score(y_sig_test, rfsig_predictions)\n",
    "rfsig_conf_mat = confusion_matrix(y_sig_test, rfsig_predictions)\n",
    "rfsig_class_report = classification_report(y_sig_test, rfsig_predictions)\n",
    "\n",
    "print(f\"Accuracy: {rfsig_accuracy:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", rfsig_conf_mat)\n",
    "print(\"\\nClassification Report:\\n\", rfsig_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d339358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
